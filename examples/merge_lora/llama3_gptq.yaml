# model
model_name_or_path: unsloth/llama-3-8b-Instruct-bnb-4bit
template: llama3

# export
export_dir: models/llama3_gptq
export_quantization_bit: 4
export_quantization_dataset: data/rgm_knowledge.json
export_size: 2
export_device: cpu
export_legacy_format: false
